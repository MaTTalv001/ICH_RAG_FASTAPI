import streamlit as st
from processor import ICHGuidelineProcessor
from qa import ICHGuidelineQA
import os
import glob
import pandas as pd
from ich_downloader import ICHDownloader

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ãªã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä¿æŒ
@st.cache_resource
def initialize_qa_system():
    # vectorstoreã®ãƒ‘ã‚¹ã¯å…±æœ‰ãƒœãƒªãƒ¥ãƒ¼ãƒ ã®ãƒ‘ã‚¹ã‚’ä½¿ç”¨
    return ICHGuidelineQA(persist_directory="/vectorstore/ich_db")

if "qa_system" not in st.session_state:
    st.session_state.qa_system = initialize_qa_system()

st.title("ICH Guidelines Q&A System")

# ä»¥ä¸‹ã®éƒ¨åˆ†ã¯å¤‰æ›´ãªã—
mode = st.sidebar.radio(
    "ãƒ¢ãƒ¼ãƒ‰é¸æŠ",
    ["ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¢ãƒ¼ãƒ‰", "åéŒ²ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³è¡¨ç¤º", "ç®¡ç†è€…ãƒ¢ãƒ¼ãƒ‰"],
    index=0
)

if mode == "ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¢ãƒ¼ãƒ‰":
    st.header("ICHã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³Q&A")
    
    try:
        # vectorstoreã®ãƒ‘ã‚¹ã‚’ä¿®æ­£
        qa_system = ICHGuidelineQA(persist_directory="/vectorstore/ich_db")
        
        # ä»¥ä¸‹ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¢ãƒ¼ãƒ‰ã®å‡¦ç†ã¯å¤‰æ›´ãªã—
        question = st.text_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        
        if question:
            with st.spinner("å›ç­”ã‚’ç”Ÿæˆä¸­..."):
                answer = qa_system.answer_question(question)
                sources = qa_system.get_relevant_sources(question)
            
            st.markdown("### ğŸ’¡ å›ç­”")
            st.markdown(f">{answer}")
            
            st.markdown("### ğŸ“š å‚ç…§ã‚½ãƒ¼ã‚¹")
            tabs = st.tabs([f"ã‚½ãƒ¼ã‚¹ {i+1}" for i in range(len(sources))])
            
            for tab, source in zip(tabs, sources):
                with tab:
                    st.markdown(f"**ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³:** {source['title']} ({source['code']})")
                    filename = source.get('source_file')
                    if filename:
                        url = f"https://www.pmda.go.jp/files/{filename}"
                        st.markdown(f"[å…ƒã®PDFã‚’é–‹ã]({url}) ğŸ“„")
                    st.markdown(f"**ã‚«ãƒ†ã‚´ãƒª:** {source['category']}")
                    st.markdown("**é–¢é€£ç®‡æ‰€:**")
                    st.text_area(
                        label="",
                        value=source['preview'],
                        height=300,
                        disabled=False
                    )
    except Exception as e:
        st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")

elif mode == "åéŒ²ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³è¡¨ç¤º":
    st.header("åéŒ²ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ä¸€è¦§")
    # ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã¯å…±æœ‰ãƒœãƒªãƒ¥ãƒ¼ãƒ ã®ãƒ‘ã‚¹ã‚’ä½¿ç”¨
    df = pd.read_csv("/data/dataset/ich.csv")
    st.dataframe(df)

else:  # ç®¡ç†è€…ãƒ¢ãƒ¼ãƒ‰
    st.warning("âš ï¸ ç®¡ç†è€…ãƒ¢ãƒ¼ãƒ‰ã§ã™ã€‚ã‚·ã‚¹ãƒ†ãƒ ã®è¨­å®šå¤‰æ›´ãŒå¯èƒ½ã§ã™ã€‚")
    
    admin_mode = st.radio(
        "ç®¡ç†æ©Ÿèƒ½ã‚’é¸æŠ",
        ["ãƒ™ã‚¯ãƒˆãƒ«åŒ–", "ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç®¡ç†"]
    )

    if admin_mode == "ãƒ™ã‚¯ãƒˆãƒ«åŒ–":
        st.header("ICHã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã®ãƒ™ã‚¯ãƒˆãƒ«åŒ–")
        if st.button("ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã‚’å®Ÿè¡Œ"):
            try:
                # ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹ã‚’å…±æœ‰ãƒœãƒªãƒ¥ãƒ¼ãƒ ã®ãƒ‘ã‚¹ã«å¤‰æ›´
                data_dir = "/data/ich_guidelines"
                if not os.path.exists(data_dir):
                    st.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {data_dir}")
                    st.stop()

                json_files = glob.glob(os.path.join(data_dir, "*.json"))
                if not json_files:
                    st.error(f"JSONãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {data_dir}")
                    st.stop()

                # vectorstoreã®ãƒ‘ã‚¹ã‚’å…±æœ‰ãƒœãƒªãƒ¥ãƒ¼ãƒ ã®ãƒ‘ã‚¹ã«å¤‰æ›´
                processor = ICHGuidelineProcessor(persist_directory="/vectorstore/ich_db")
                all_chunks = []

                with st.spinner("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ä¸­..."):
                    for json_file in json_files:
                        base_name = os.path.splitext(json_file)[0]
                        txt_file = base_name + '.txt'
                        
                        if os.path.exists(txt_file):
                            doc = processor.process_files(json_file, txt_file)
                            chunks = processor.split_document(doc)
                            all_chunks.extend(chunks)
                            st.write(f"å‡¦ç†å®Œäº†: {os.path.basename(json_file)}")

                if all_chunks:
                    with st.spinner("ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã‚’ä½œæˆä¸­..."):
                        vectorstore = processor.create_vectorstore(all_chunks)
                    st.success(f"ãƒ™ã‚¯ãƒˆãƒ«åŒ–ãŒå®Œäº†ã—ã¾ã—ãŸã€‚{len(all_chunks)}ãƒãƒ£ãƒ³ã‚¯ã‚’å‡¦ç†ã—ã¾ã—ãŸã€‚")
                else:
                    st.warning("å‡¦ç†å¯èƒ½ãªãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")

            except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")

    else:  # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç®¡ç†
        st.header("ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç®¡ç†")
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’å…±æœ‰ãƒœãƒªãƒ¥ãƒ¼ãƒ ã®ãƒ‘ã‚¹ã«å¤‰æ›´
        df = pd.read_csv("/data/dataset/ich.csv")
        st.dataframe(df)
        
        if st.button("ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"):
            try:
                downloader = ICHDownloader()
                downloader.process_all(df)
            except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")